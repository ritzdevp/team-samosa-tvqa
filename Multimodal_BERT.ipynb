{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multimodal_BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPL1tRJ+6KlKILHjEhCeJbp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ritzdevp/team-samosa-tvqa/blob/main/Multimodal_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHmm2JWP8dOQ",
        "outputId": "9f3bca8c-2b65-4578-cfe9-ecc1ef0867c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'team-samosa-tvqa'...\n",
            "remote: Enumerating objects: 253, done.\u001b[K\n",
            "remote: Counting objects: 100% (2/2), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 253 (delta 1), reused 0 (delta 0), pack-reused 251\u001b[K\n",
            "Receiving objects: 100% (253/253), 1.28 MiB | 11.90 MiB/s, done.\n",
            "Resolving deltas: 100% (137/137), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ritzdevp/team-samosa-tvqa"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1m8bC4lefQsP2tRhMLAaiy0AVuBXZtegc' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1m8bC4lefQsP2tRhMLAaiy0AVuBXZtegc\" -O tvqa_imagenet_resnet101_pool5_hq.tar.gz && rm -rf /tmp/cookies.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuP5ePiy8wwN",
        "outputId": "52bd0fa5-4ab9-4386-cb37-a777dc1c3a9c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-26 17:37:28--  https://docs.google.com/uc?export=download&confirm=t&id=1m8bC4lefQsP2tRhMLAaiy0AVuBXZtegc\n",
            "Resolving docs.google.com (docs.google.com)... 108.177.126.101, 108.177.126.139, 108.177.126.100, ...\n",
            "Connecting to docs.google.com (docs.google.com)|108.177.126.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0k-6g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/0j84m115ul5n7ct8c6o70clau6rltr4b/1650994575000/07218467666063224277/*/1m8bC4lefQsP2tRhMLAaiy0AVuBXZtegc?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-04-26 17:37:28--  https://doc-0k-6g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/0j84m115ul5n7ct8c6o70clau6rltr4b/1650994575000/07218467666063224277/*/1m8bC4lefQsP2tRhMLAaiy0AVuBXZtegc?e=download\n",
            "Resolving doc-0k-6g-docs.googleusercontent.com (doc-0k-6g-docs.googleusercontent.com)... 172.217.218.132, 2a00:1450:4013:c08::84\n",
            "Connecting to doc-0k-6g-docs.googleusercontent.com (doc-0k-6g-docs.googleusercontent.com)|172.217.218.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 36530196109 (34G) [application/x-gzip]\n",
            "Saving to: ‘tvqa_imagenet_resnet101_pool5_hq.tar.gz’\n",
            "\n",
            "tvqa_imagenet_resne 100%[===================>]  34.02G   125MB/s    in 4m 51s  \n",
            "\n",
            "2022-04-26 17:42:20 (120 MB/s) - ‘tvqa_imagenet_resnet101_pool5_hq.tar.gz’ saved [36530196109/36530196109]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! tar xzf /content/tvqa_imagenet_resnet101_pool5_hq.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k79jTHe9-vlX",
        "outputId": "d62dca28-9c82-45ed-aa5b-2f04f1ac4434"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers datasets"
      ],
      "metadata": {
        "id": "hDG6HKbZ8xJj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "import transformers\n",
        "from transformers import BertTokenizer, VisualBertForQuestionAnswering, VisualBertModel"
      ],
      "metadata": {
        "id": "2-tsiNF08_bE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\",  output_hidden_states = True)\n",
        "bert_model = VisualBertModel.from_pretrained(\"uclanlp/visualbert-vqa-coco-pre\",  output_hidden_states = True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8wxe3bm__p0",
        "outputId": "a9aac7de-b214-42eb-94b1-e7407ad22660"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at uclanlp/visualbert-vqa-coco-pre were not used when initializing VisualBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing VisualBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing VisualBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "% cd /content/team-samosa-tvqa/baseline_repo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lq8Nl5G4bncZ",
        "outputId": "529ff910-4777-4840-a538-a8c8ab6746f5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/team-samosa-tvqa/baseline_repo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 777 /content/team-samosa-tvqa/baseline_repo/setup.sh"
      ],
      "metadata": {
        "id": "B6YhEaysbsyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! /content/team-samosa-tvqa/baseline_repo/setup.sh"
      ],
      "metadata": {
        "id": "ULuNTvbjbu22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#debugging\n",
        "import h5py\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from CONSTANTS import RESNET_FEATURES\n",
        "\n",
        "h5driver=None\n",
        "vid_feat_path=RESNET_FEATURES\n",
        "vid_h5 = h5py.File(vid_feat_path, \"r\", driver=h5driver)\n",
        "\n",
        "def read_resnet_feats(video_names, stride=8):\n",
        "    video_resnet_feat = []\n",
        "    for video in video_names:\n",
        "        video_resnet_feat.append(torch.tensor(vid_h5[video][::stride, :], device=\"cuda\"))\n",
        "\n",
        "    video_resnet_feat =  pad_sequence(video_resnet_feat, batch_first=True)\n",
        "    \n",
        "    return video_resnet_feat"
      ],
      "metadata": {
        "id": "KYx7JNj1biEm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TVQA_Multimodal(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super(TVQA_Multimodal, self).__init__()\n",
        "\n",
        "        self.bert_tokenizer = bert_tokenizer\n",
        "        self.bert_model = bert_model.to(\"cuda\")\n",
        "\n",
        "        self.proj = torch.nn.Sequential(torch.nn.Linear(768, 256),\n",
        "                                        torch.nn.GELU(),\n",
        "                                        torch.nn.Linear(256, 64),\n",
        "                                        torch.nn.GELU(),\n",
        "                                        torch.nn.Linear(64, 1)).to(\"cuda\")\n",
        "\n",
        "    def _freeze_bert_weights(self, requires_grad_layers = ['encoder.layer.11', \n",
        "                                                           'pooler.dense.weight',\n",
        "                                                           'pooler.dense.bias']):\n",
        "        for name, p in self.bert_model.named_parameters():\n",
        "            req_grad = False\n",
        "            for layer_name in requires_grad_layers:\n",
        "                if layer_name in name:\n",
        "                    req_grad = True\n",
        "                    break\n",
        "\n",
        "            p.requires_grad = req_grad\n",
        "        \n",
        "        return True\n",
        "\n",
        "    def merge_q_ans(self, que, ans):\n",
        "        merged = []\n",
        "        for i in range(len(que)):\n",
        "          curr = que[i]+ ' [SEP] ' + ans[i]\n",
        "          merged.append(curr)\n",
        "        return merged\n",
        "\n",
        "    def bert_forward(self, question, ans, subt_text, video_names):\n",
        "\n",
        "        merge_q_ans = self.merge_q_ans(question, ans)\n",
        "\n",
        "        inputs       = bert_tokenizer(subt_text, \n",
        "                                      merge_q_ans,  \n",
        "                                      padding=\"max_length\",\n",
        "                                      truncation=True,\n",
        "                                      return_token_type_ids=True,\n",
        "                                      return_attention_mask=True,\n",
        "                                      add_special_tokens=True,\n",
        "                                      return_tensors=\"pt\")\n",
        "        \n",
        "        \n",
        "        visual_embeds = read_resnet_feats(video_names)\n",
        "\n",
        "        visual_token_type_ids = torch.ones(visual_embeds.shape[:-1], dtype=torch.long).to(\"cuda\")\n",
        "        visual_attention_mask = torch.ones(visual_embeds.shape[:-1], dtype=torch.float).to(\"cuda\")\n",
        "        inputs.update(\n",
        "            {\n",
        "                \"visual_embeds\": visual_embeds,\n",
        "                \"visual_token_type_ids\": visual_token_type_ids,\n",
        "                \"visual_attention_mask\": visual_attention_mask,\n",
        "            }\n",
        "        )\n",
        "        inputs = inputs.to(\"cuda\")\n",
        "\n",
        "        output = bert_model(**inputs)\n",
        "\n",
        "        hidden_states = output.last_hidden_state\n",
        "        cls_tokens = hidden_states[:,0,:]\n",
        "\n",
        "        return cls_tokens\n",
        "\n",
        "    def forward(self, question, subt_text, a0, a1, a2, a3, a4, video_names):\n",
        "\n",
        "        bert_a0 = self.bert_forward(question=question,\n",
        "                                    ans=a0,\n",
        "                                    subt_text=subt_text,\n",
        "                                    video_names=video_names)        \n",
        "        score_a0 = self.proj(bert_a0)\n",
        "\n",
        "        bert_a1 = self.bert_forward(question=question,\n",
        "                                    ans=a1,\n",
        "                                    subt_text=subt_text,\n",
        "                                    video_names=video_names)\n",
        "        score_a1 = self.proj(bert_a1)\n",
        "\n",
        "        bert_a2 = self.bert_forward(question=question,\n",
        "                                    ans=a2,\n",
        "                                    subt_text=subt_text,\n",
        "                                    video_names=video_names)\n",
        "        score_a2 = self.proj(bert_a2)\n",
        "\n",
        "        bert_a3 = self.bert_forward(question=question,\n",
        "                                    ans=a3,\n",
        "                                    subt_text=subt_text,\n",
        "                                    video_names=video_names)\n",
        "        \n",
        "        score_a3 = self.proj(bert_a3)\n",
        "\n",
        "        bert_a4 = self.bert_forward(question=question,\n",
        "                                    ans=a4,\n",
        "                                    subt_text=subt_text,\n",
        "                                    video_names=video_names)\n",
        "        \n",
        "        score_a4 = self.proj(bert_a4)\n",
        "\n",
        "        # print(\" score_a4 \", score_a4.shape)\n",
        "\n",
        "\n",
        "        logits = torch.cat((score_a0, score_a1, score_a2, score_a3, score_a4), dim=1)\n",
        "\n",
        "        # print(\" logits \", logits.shape)\n",
        "\n",
        "\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "1vAyQMnp9GBh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from CONSTANTS import  BASE_PATH\n",
        "import json"
      ],
      "metadata": {
        "id": "XYnj5IN1MtqZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class TVQAPlus(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset='train'):\n",
        "        # sample represent how many npy files will be preloaded for one __getitem__ call\n",
        "        TRAIN_DICT_JSON = BASE_PATH + \"/tvqa_plus/tvqa_plus_train.json\"\n",
        "        VAL_DICT_JSON = BASE_PATH + '/tvqa_plus/tvqa_plus_val.json'\n",
        "        SUBTITLES_DICT_JSON = BASE_PATH + '/tvqa_plus/tvqa_plus_subtitles.json'\n",
        "\n",
        "        self.dataset = dataset\n",
        "\n",
        "        train_dict = {}\n",
        "        val_dict = {}\n",
        "        subtitles_dict = {}\n",
        "\n",
        "        with open(TRAIN_DICT_JSON) as f:\n",
        "          train_dict = json.load(f)\n",
        "\n",
        "        with open(VAL_DICT_JSON) as f:\n",
        "          val_dict = json.load(f)\n",
        "\n",
        "        with open(SUBTITLES_DICT_JSON) as f:\n",
        "          self.subtitles_dict = json.load(f)\n",
        "\n",
        "        self.target_dict = {}\n",
        "        if self.dataset == 'train':\n",
        "          self.target_dict = train_dict\n",
        "        elif self.dataset == 'val':\n",
        "          self.target_dict = val_dict\n",
        "        else:\n",
        "          raise Exception(f\"Invalid dataset passed {self.dataset}\")\n",
        "      \n",
        "    def __len__(self):\n",
        "        return len(self.target_dict)\n",
        "        \n",
        "    def __getitem__(self, i):\n",
        "\n",
        "      question = self.target_dict[i]['q']\n",
        "    \n",
        "      a0       = self.target_dict[i]['a0']\n",
        "      a1       = self.target_dict[i]['a1']\n",
        "      a2       = self.target_dict[i]['a2']\n",
        "      a3       = self.target_dict[i]['a3']\n",
        "      a4       = self.target_dict[i]['a4']\n",
        "\n",
        "      answer_idx = int(self.target_dict[i]['answer_idx'])\n",
        "      \n",
        "      video_name = self.target_dict[i]['vid_name']\n",
        "      subtitle = self.subtitles_dict[video_name]\n",
        "      subt_text = subtitle['sub_text']\n",
        "\n",
        "      return question, subt_text, a0, a1, a2, a3, a4, video_name, answer_idx"
      ],
      "metadata": {
        "id": "c-U-TdY7G32d"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TVQAPlus('train')\n",
        "test_dataset = TVQAPlus(\"val\")"
      ],
      "metadata": {
        "id": "049VKQuMN5hZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=20\n",
        "dev_batch_size=12"
      ],
      "metadata": {
        "id": "ishB5PCRlfgn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader  = torch.utils.data.DataLoader(test_dataset, batch_size=dev_batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "tAGjKdomOMPU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge(que, ans):\n",
        "  merged = []\n",
        "  for i in range(len(que)):\n",
        "    curr = que[i]+ ' [SEP] ' + ans[i]\n",
        "    merged.append(curr)\n",
        "  return merged"
      ],
      "metadata": {
        "id": "_gdg1GHUPuwS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tvqa_model = TVQA_Multimodal()\n",
        "# tvqa_model._freeze_bert_weights()\n",
        "\n",
        "print(tvqa_model.named_parameters())\n",
        "\n",
        "for name, p in tvqa_model.named_parameters():\n",
        "    print(\"name\", name, \"p\", p.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQacAgViSOsi",
        "outputId": "60a5dd97-e194-420b-83e9-f8cd392143e7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<generator object Module.named_parameters at 0x7f91a24b2850>\n",
            "name bert_model.embeddings.word_embeddings.weight p True\n",
            "name bert_model.embeddings.position_embeddings.weight p True\n",
            "name bert_model.embeddings.token_type_embeddings.weight p True\n",
            "name bert_model.embeddings.LayerNorm.weight p True\n",
            "name bert_model.embeddings.LayerNorm.bias p True\n",
            "name bert_model.embeddings.visual_token_type_embeddings.weight p True\n",
            "name bert_model.embeddings.visual_position_embeddings.weight p True\n",
            "name bert_model.embeddings.visual_projection.weight p True\n",
            "name bert_model.embeddings.visual_projection.bias p True\n",
            "name bert_model.encoder.layer.0.attention.self.query.weight p True\n",
            "name bert_model.encoder.layer.0.attention.self.query.bias p True\n",
            "name bert_model.encoder.layer.0.attention.self.key.weight p True\n",
            "name bert_model.encoder.layer.0.attention.self.key.bias p True\n",
            "name bert_model.encoder.layer.0.attention.self.value.weight p True\n",
            "name bert_model.encoder.layer.0.attention.self.value.bias p True\n",
            "name bert_model.encoder.layer.0.attention.output.dense.weight p True\n",
            "name bert_model.encoder.layer.0.attention.output.dense.bias p True\n",
            "name bert_model.encoder.layer.0.attention.output.LayerNorm.weight p True\n",
            "name bert_model.encoder.layer.0.attention.output.LayerNorm.bias p True\n",
            "name bert_model.encoder.layer.0.intermediate.dense.weight p True\n",
            "name bert_model.encoder.layer.0.intermediate.dense.bias p True\n",
            "name bert_model.encoder.layer.0.output.dense.weight p True\n",
            "name bert_model.encoder.layer.0.output.dense.bias p True\n",
            "name bert_model.encoder.layer.0.output.LayerNorm.weight p True\n",
            "name bert_model.encoder.layer.0.output.LayerNorm.bias p True\n",
            "name bert_model.encoder.layer.1.attention.self.query.weight p True\n",
            "name bert_model.encoder.layer.1.attention.self.query.bias p True\n",
            "name bert_model.encoder.layer.1.attention.self.key.weight p True\n",
            "name bert_model.encoder.layer.1.attention.self.key.bias p True\n",
            "name bert_model.encoder.layer.1.attention.self.value.weight p True\n",
            "name bert_model.encoder.layer.1.attention.self.value.bias p True\n",
            "name bert_model.encoder.layer.1.attention.output.dense.weight p True\n",
            "name bert_model.encoder.layer.1.attention.output.dense.bias p True\n",
            "name bert_model.encoder.layer.1.attention.output.LayerNorm.weight p True\n",
            "name bert_model.encoder.layer.1.attention.output.LayerNorm.bias p True\n",
            "name bert_model.encoder.layer.1.intermediate.dense.weight p True\n",
            "name bert_model.encoder.layer.1.intermediate.dense.bias p True\n",
            "name bert_model.encoder.layer.1.output.dense.weight p True\n",
            "name bert_model.encoder.layer.1.output.dense.bias p True\n",
            "name bert_model.encoder.layer.1.output.LayerNorm.weight p True\n",
            "name bert_model.encoder.layer.1.output.LayerNorm.bias p True\n",
            "name bert_model.encoder.layer.2.attention.self.query.weight p True\n",
            "name bert_model.encoder.layer.2.attention.self.query.bias p True\n",
            "name bert_model.encoder.layer.2.attention.self.key.weight p True\n",
            "name bert_model.encoder.layer.2.attention.self.key.bias p True\n",
            "name bert_model.encoder.layer.2.attention.self.value.weight p True\n",
            "name bert_model.encoder.layer.2.attention.self.value.bias p True\n",
            "name bert_model.encoder.layer.2.attention.output.dense.weight p True\n",
            "name bert_model.encoder.layer.2.attention.output.dense.bias p True\n",
            "name bert_model.encoder.layer.2.attention.output.LayerNorm.weight p True\n",
            "name bert_model.encoder.layer.2.attention.output.LayerNorm.bias p True\n",
            "name bert_model.encoder.layer.2.intermediate.dense.weight p True\n",
            "name bert_model.encoder.layer.2.intermediate.dense.bias p True\n",
            "name bert_model.encoder.layer.2.output.dense.weight p True\n",
            "name bert_model.encoder.layer.2.output.dense.bias p True\n",
            "name bert_model.encoder.layer.2.output.LayerNorm.weight p True\n",
            "name bert_model.encoder.layer.2.output.LayerNorm.bias p True\n",
            "name bert_model.encoder.layer.3.attention.self.query.weight p True\n",
            "name bert_model.encoder.layer.3.attention.self.query.bias p True\n",
            "name bert_model.encoder.layer.3.attention.self.key.weight p True\n",
            "name bert_model.encoder.layer.3.attention.self.key.bias p True\n",
            "name bert_model.encoder.layer.3.attention.self.value.weight p True\n",
            "name bert_model.encoder.layer.3.attention.self.value.bias p True\n",
            "name bert_model.encoder.layer.3.attention.output.dense.weight p True\n",
            "name bert_model.encoder.layer.3.attention.output.dense.bias p True\n",
            "name bert_model.encoder.layer.3.attention.output.LayerNorm.weight p True\n",
            "name bert_model.encoder.layer.3.attention.output.LayerNorm.bias p True\n",
            "name bert_model.encoder.layer.3.intermediate.dense.weight p True\n",
            "name bert_model.encoder.layer.3.intermediate.dense.bias p True\n",
            "name bert_model.encoder.layer.3.output.dense.weight p True\n",
            "name bert_model.encoder.layer.3.output.dense.bias p True\n",
            "name bert_model.encoder.layer.3.output.LayerNorm.weight p True\n",
            "name bert_model.encoder.layer.3.output.LayerNorm.bias p True\n",
            "name bert_model.encoder.layer.4.attention.self.query.weight p True\n",
            "name bert_model.encoder.layer.4.attention.self.query.bias p True\n",
            "name bert_model.encoder.layer.4.attention.self.key.weight p True\n",
            "name bert_model.encoder.layer.4.attention.self.key.bias p True\n",
            "name bert_model.encoder.layer.4.attention.self.value.weight p True\n",
            "name bert_model.encoder.layer.4.attention.self.value.bias p True\n",
            "name bert_model.encoder.layer.4.attention.output.dense.weight p True\n",
            "name bert_model.encoder.layer.4.attention.output.dense.bias p True\n",
            "name bert_model.encoder.layer.4.attention.output.LayerNorm.weight p True\n",
            "name bert_model.encoder.layer.4.attention.output.LayerNorm.bias p True\n",
            "name bert_model.encoder.layer.4.intermediate.dense.weight p True\n",
            "name bert_model.encoder.layer.4.intermediate.dense.bias p True\n",
            "name bert_model.encoder.layer.4.output.dense.weight p True\n",
            "name bert_model.encoder.layer.4.output.dense.bias p True\n",
            "name bert_model.encoder.layer.4.output.LayerNorm.weight p True\n",
            "name bert_model.encoder.layer.4.output.LayerNorm.bias p True\n",
            "name bert_model.encoder.layer.5.attention.self.query.weight p True\n",
            "name bert_model.encoder.layer.5.attention.self.query.bias p True\n",
            "name bert_model.encoder.layer.5.attention.self.key.weight p True\n",
            "name bert_model.encoder.layer.5.attention.self.key.bias p True\n",
            "name bert_model.encoder.layer.5.attention.self.value.weight p True\n",
            "name bert_model.encoder.layer.5.attention.self.value.bias p True\n",
            "name bert_model.encoder.layer.5.attention.output.dense.weight p True\n",
            "name bert_model.encoder.layer.5.attention.output.dense.bias p True\n",
            "name bert_model.encoder.layer.5.attention.output.LayerNorm.weight p True\n",
            "name bert_model.encoder.layer.5.attention.output.LayerNorm.bias p True\n",
            "name bert_model.encoder.layer.5.intermediate.dense.weight p True\n",
            "name bert_model.encoder.layer.5.intermediate.dense.bias p True\n",
            "name bert_model.encoder.layer.5.output.dense.weight p True\n",
            "name bert_model.encoder.layer.5.output.dense.bias p True\n",
            "name bert_model.encoder.layer.5.output.LayerNorm.weight p True\n",
            "name bert_model.encoder.layer.5.output.LayerNorm.bias p True\n",
            "name bert_model.encoder.layer.6.attention.self.query.weight p True\n",
            "name bert_model.encoder.layer.6.attention.self.query.bias p True\n",
            "name bert_model.encoder.layer.6.attention.self.key.weight p True\n",
            "name bert_model.encoder.layer.6.attention.self.key.bias p True\n",
            "name bert_model.encoder.layer.6.attention.self.value.weight p True\n",
            "name bert_model.encoder.layer.6.attention.self.value.bias p True\n",
            "name bert_model.encoder.layer.6.attention.output.dense.weight p True\n",
            "name bert_model.encoder.layer.6.attention.output.dense.bias p True\n",
            "name bert_model.encoder.layer.6.attention.output.LayerNorm.weight p True\n",
            "name bert_model.encoder.layer.6.attention.output.LayerNorm.bias p True\n",
            "name bert_model.encoder.layer.6.intermediate.dense.weight p True\n",
            "name bert_model.encoder.layer.6.intermediate.dense.bias p True\n",
            "name bert_model.encoder.layer.6.output.dense.weight p True\n",
            "name bert_model.encoder.layer.6.output.dense.bias p True\n",
            "name bert_model.encoder.layer.6.output.LayerNorm.weight p True\n",
            "name bert_model.encoder.layer.6.output.LayerNorm.bias p True\n",
            "name bert_model.encoder.layer.7.attention.self.query.weight p True\n",
            "name bert_model.encoder.layer.7.attention.self.query.bias p True\n",
            "name bert_model.encoder.layer.7.attention.self.key.weight p True\n",
            "name bert_model.encoder.layer.7.attention.self.key.bias p True\n",
            "name bert_model.encoder.layer.7.attention.self.value.weight p True\n",
            "name bert_model.encoder.layer.7.attention.self.value.bias p True\n",
            "name bert_model.encoder.layer.7.attention.output.dense.weight p True\n",
            "name bert_model.encoder.layer.7.attention.output.dense.bias p True\n",
            "name bert_model.encoder.layer.7.attention.output.LayerNorm.weight p True\n",
            "name bert_model.encoder.layer.7.attention.output.LayerNorm.bias p True\n",
            "name bert_model.encoder.layer.7.intermediate.dense.weight p True\n",
            "name bert_model.encoder.layer.7.intermediate.dense.bias p True\n",
            "name bert_model.encoder.layer.7.output.dense.weight p True\n",
            "name bert_model.encoder.layer.7.output.dense.bias p True\n",
            "name bert_model.encoder.layer.7.output.LayerNorm.weight p True\n",
            "name bert_model.encoder.layer.7.output.LayerNorm.bias p True\n",
            "name bert_model.encoder.layer.8.attention.self.query.weight p True\n",
            "name bert_model.encoder.layer.8.attention.self.query.bias p True\n",
            "name bert_model.encoder.layer.8.attention.self.key.weight p True\n",
            "name bert_model.encoder.layer.8.attention.self.key.bias p True\n",
            "name bert_model.encoder.layer.8.attention.self.value.weight p True\n",
            "name bert_model.encoder.layer.8.attention.self.value.bias p True\n",
            "name bert_model.encoder.layer.8.attention.output.dense.weight p True\n",
            "name bert_model.encoder.layer.8.attention.output.dense.bias p True\n",
            "name bert_model.encoder.layer.8.attention.output.LayerNorm.weight p True\n",
            "name bert_model.encoder.layer.8.attention.output.LayerNorm.bias p True\n",
            "name bert_model.encoder.layer.8.intermediate.dense.weight p True\n",
            "name bert_model.encoder.layer.8.intermediate.dense.bias p True\n",
            "name bert_model.encoder.layer.8.output.dense.weight p True\n",
            "name bert_model.encoder.layer.8.output.dense.bias p True\n",
            "name bert_model.encoder.layer.8.output.LayerNorm.weight p True\n",
            "name bert_model.encoder.layer.8.output.LayerNorm.bias p True\n",
            "name bert_model.encoder.layer.9.attention.self.query.weight p True\n",
            "name bert_model.encoder.layer.9.attention.self.query.bias p True\n",
            "name bert_model.encoder.layer.9.attention.self.key.weight p True\n",
            "name bert_model.encoder.layer.9.attention.self.key.bias p True\n",
            "name bert_model.encoder.layer.9.attention.self.value.weight p True\n",
            "name bert_model.encoder.layer.9.attention.self.value.bias p True\n",
            "name bert_model.encoder.layer.9.attention.output.dense.weight p True\n",
            "name bert_model.encoder.layer.9.attention.output.dense.bias p True\n",
            "name bert_model.encoder.layer.9.attention.output.LayerNorm.weight p True\n",
            "name bert_model.encoder.layer.9.attention.output.LayerNorm.bias p True\n",
            "name bert_model.encoder.layer.9.intermediate.dense.weight p True\n",
            "name bert_model.encoder.layer.9.intermediate.dense.bias p True\n",
            "name bert_model.encoder.layer.9.output.dense.weight p True\n",
            "name bert_model.encoder.layer.9.output.dense.bias p True\n",
            "name bert_model.encoder.layer.9.output.LayerNorm.weight p True\n",
            "name bert_model.encoder.layer.9.output.LayerNorm.bias p True\n",
            "name bert_model.encoder.layer.10.attention.self.query.weight p True\n",
            "name bert_model.encoder.layer.10.attention.self.query.bias p True\n",
            "name bert_model.encoder.layer.10.attention.self.key.weight p True\n",
            "name bert_model.encoder.layer.10.attention.self.key.bias p True\n",
            "name bert_model.encoder.layer.10.attention.self.value.weight p True\n",
            "name bert_model.encoder.layer.10.attention.self.value.bias p True\n",
            "name bert_model.encoder.layer.10.attention.output.dense.weight p True\n",
            "name bert_model.encoder.layer.10.attention.output.dense.bias p True\n",
            "name bert_model.encoder.layer.10.attention.output.LayerNorm.weight p True\n",
            "name bert_model.encoder.layer.10.attention.output.LayerNorm.bias p True\n",
            "name bert_model.encoder.layer.10.intermediate.dense.weight p True\n",
            "name bert_model.encoder.layer.10.intermediate.dense.bias p True\n",
            "name bert_model.encoder.layer.10.output.dense.weight p True\n",
            "name bert_model.encoder.layer.10.output.dense.bias p True\n",
            "name bert_model.encoder.layer.10.output.LayerNorm.weight p True\n",
            "name bert_model.encoder.layer.10.output.LayerNorm.bias p True\n",
            "name bert_model.encoder.layer.11.attention.self.query.weight p True\n",
            "name bert_model.encoder.layer.11.attention.self.query.bias p True\n",
            "name bert_model.encoder.layer.11.attention.self.key.weight p True\n",
            "name bert_model.encoder.layer.11.attention.self.key.bias p True\n",
            "name bert_model.encoder.layer.11.attention.self.value.weight p True\n",
            "name bert_model.encoder.layer.11.attention.self.value.bias p True\n",
            "name bert_model.encoder.layer.11.attention.output.dense.weight p True\n",
            "name bert_model.encoder.layer.11.attention.output.dense.bias p True\n",
            "name bert_model.encoder.layer.11.attention.output.LayerNorm.weight p True\n",
            "name bert_model.encoder.layer.11.attention.output.LayerNorm.bias p True\n",
            "name bert_model.encoder.layer.11.intermediate.dense.weight p True\n",
            "name bert_model.encoder.layer.11.intermediate.dense.bias p True\n",
            "name bert_model.encoder.layer.11.output.dense.weight p True\n",
            "name bert_model.encoder.layer.11.output.dense.bias p True\n",
            "name bert_model.encoder.layer.11.output.LayerNorm.weight p True\n",
            "name bert_model.encoder.layer.11.output.LayerNorm.bias p True\n",
            "name bert_model.pooler.dense.weight p True\n",
            "name bert_model.pooler.dense.bias p True\n",
            "name proj.0.weight p True\n",
            "name proj.0.bias p True\n",
            "name proj.2.weight p True\n",
            "name proj.2.bias p True\n",
            "name proj.4.weight p True\n",
            "name proj.4.bias p True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def val_acc(model, dev_loader, batch_size_dev):\n",
        "  model.eval()\n",
        "  num_correct = 0\n",
        "  for batch_idx, ( question, subt_text, a0, a1, a2, a3, a4, video_names, answer_idx) in enumerate(test_loader):\n",
        "    answer_idx = answer_idx.to(\"cuda\")\n",
        "    with torch.no_grad():\n",
        "      # # IF MODEL does not TAKES VIDEO INPUT\n",
        "\n",
        "      logits = model.forward(question, subt_text, a0, a1, a2, a3, a4, video_names)\n",
        "\n",
        "      \n",
        "    num_correct += int((torch.argmax(logits, axis=1) == answer_idx).sum())\n",
        "    acc = 100 * num_correct / ((batch_idx + 1) * batch_size_dev)\n",
        "\n",
        "  dev_acc = 100 * num_correct / (len(dev_loader) * batch_size_dev)\n",
        "\n",
        "  model.train()\n",
        "  return dev_acc"
      ],
      "metadata": {
        "id": "MEh2Hhvlmefj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "optimizer = optim.Adam(tvqa_model.parameters(), lr=1e-3)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)"
      ],
      "metadata": {
        "id": "LIvDHgmTkg8l"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Set the verbosity level as follows:\n",
        "\n",
        "transformers.logging.set_verbosity_error()\n",
        "\n",
        "\n",
        "# bert_model.cuda()\n",
        "\n",
        "num_correct = 0\n",
        "\n",
        "epoch = 0\n",
        "best_dev_acc = 0\n",
        "loss_epoch = 0\n",
        "\n",
        "while epoch < 100:\n",
        "  \n",
        "    batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train')\n",
        "    tvqa_model.train()\n",
        "\n",
        "    for batch_idx, ( question, subt_text, a0, a1, a2, a3, a4, video_names, answer_idx) in enumerate(train_loader):\n",
        "\n",
        "        logits = tvqa_model.forward(question, subt_text, a0, a1, a2, a3, a4, video_names)\n",
        "        answer_idx = answer_idx.to(\"cuda\")\n",
        "        loss = criterion(logits, answer_idx)\n",
        "        num_correct += int((torch.argmax(logits, axis=1) == answer_idx).sum())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss_epoch += float(loss)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        batch_bar.set_postfix(\n",
        "            acc=\"{:.04f}%\".format(100 * num_correct / ((batch_idx + 1) * batch_size)),\n",
        "            loss=\"{:.04f}\".format(float(loss_epoch / (batch_idx + 1))),\n",
        "            num_correct=num_correct,\n",
        "            lr=\"{:.04f}\".format(float(optimizer.param_groups[0]['lr'])))\n",
        "        \n",
        "        batch_bar.update() # Update tqdm bar\n",
        "\n",
        "        # break\n",
        "\n",
        "    batch_bar.close() # You need this to close the tqdm bar\n",
        "\n",
        "    train_acc = 100 * num_correct / (len(train_loader) * batch_size)\n",
        "    dev_acc = val_acc(tvqa_model, test_loader, dev_batch_size)\n",
        "\n",
        "    print(f'Epoch {epoch} Loss {loss_epoch} train_acc {train_acc}, devacc {dev_acc}')\n",
        "        \n"
      ],
      "metadata": {
        "id": "OkZOjiffOp1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tvqa_model = TVQA_Multimodal()\n",
        "tvqa_model._freeze_bert_weights()\n",
        "# print(tvqa_model)\n",
        "# tvqa_model._free\n",
        "\n",
        "for name, p in tvqa_model.bert_model.named_parameters():\n",
        "    print(\"name\", name, \"p\", p.shape, \"p.requires_grad\", p.requires_grad)"
      ],
      "metadata": {
        "id": "2R8VlswM_db-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ojYxBI0QAfZO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}